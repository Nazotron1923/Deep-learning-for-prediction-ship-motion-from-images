current model: CNN_LSTM
best train error:8.774554958213754
best validation loss:12.273297681051588
final test loss:12.030294208829364
time to predict is (seconds):4
Time use to predict:5
Train examples (images):84000
Val examples (images):18000
Test examples (images):18000BATCH_SIZE:100
AutoEncoder(
  (encoder): Sequential(
    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): ReLU()
    (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (fc1): Linear(in_features=2688, out_features=1024, bias=True)
  (fc2): Linear(in_features=2688, out_features=1024, bias=True)
  (fc3): Linear(in_features=1024, out_features=2688, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): ReLU()
    (2): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(0, 1))
    (3): ReLU()
    (4): ConvTranspose2d(8, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): Tanh()
  )
)
LSTM_encoder(
  (lstm): LSTM(20, 300, batch_first=True)
)
LSTM_decoder(
  (lstm): LSTM(300, 300, batch_first=True)
  (out_1): Linear(in_features=300, out_features=150, bias=True)
  (out_2): Linear(in_features=150, out_features=16, bias=True)
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.001
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.001
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.001
)

