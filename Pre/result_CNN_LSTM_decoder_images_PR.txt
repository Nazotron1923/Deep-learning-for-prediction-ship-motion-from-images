current model: CNN_LSTM
best train error:2.2029498640696215
best validation loss:2.2954014873504645
final test loss:3.0162446521577384
time to predict is (seconds):5
Time use to predict:5
Train examples (images):28800
Val examples (images):7200
Test examples (images):10080BATCH_SIZE:24
AutoEncoder(
  (encoder): Sequential(
    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): ReLU()
    (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (fc1): Linear(in_features=2688, out_features=1024, bias=True)
  (fc2): Linear(in_features=2688, out_features=1024, bias=True)
  (fc3): Linear(in_features=1024, out_features=2688, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): ReLU()
    (2): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(0, 1))
    (3): ReLU()
    (4): ConvTranspose2d(8, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): Tanh()
  )
)
LSTM_decoder_simple2(
  (lstm): LSTM(10260, 1000, batch_first=True)
  (out_1): Linear(in_features=1000, out_features=500, bias=True)
  (out_2): Linear(in_features=500, out_features=20, bias=True)
  (dropout0): Dropout(p=0.2)
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0.001
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0.001
)

current model: CNN_LSTM
best train error:1.4481207275390628
best validation loss:4.252227587577623
final test loss:3.4108291479257433
time to predict is (seconds):5
Time use to predict:5
Train examples (images):79200
Val examples (images):18720
Test examples (images):18720BATCH_SIZE:24
AutoEncoder(
  (encoder): Sequential(
    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU()
    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): ReLU()
    (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (fc1): Linear(in_features=2688, out_features=1024, bias=True)
  (fc2): Linear(in_features=2688, out_features=1024, bias=True)
  (fc3): Linear(in_features=1024, out_features=2688, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): ReLU()
    (2): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(0, 1))
    (3): ReLU()
    (4): ConvTranspose2d(8, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): Tanh()
  )
)
LSTM_decoder_simple2(
  (lstm): LSTM(10260, 1000, batch_first=True)
  (out_1): Linear(in_features=1000, out_features=500, bias=True)
  (out_2): Linear(in_features=500, out_features=20, bias=True)
  (dropout0): Dropout(p=0.2)
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0.001
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0.001
)

